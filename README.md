# Master Thesis: Transformers based models improve the sentiment analysis of Peruvian congress elections 

This repository contains the implementation and results of a study exploring the use of transformer-based and hybrid models for sentiment analysis of Spanish-language Twitter comments related to Peruvian congressional elections.

The study compares traditional machine learning models (SVM, Naive Bayes) and deep learning architectures (CNN) with transformer-based models such as DistilBERT, BiLSTM-DistilBERT, and XLM-RoBERTa. Results show that transformer-based models significantly outperform traditional methods, with XLM-RoBERTa achieving the best performance due to its multilingual capabilities and contextual understanding.

The findings emphasize the importance of stop words in improving model performance and highlight the effectiveness of transformer-based architectures in capturing nuanced linguistic patterns.


Enhancing Sentiment Analysis of Spanish Twitter Comments Using Transformer-Based and Hybrid Models
